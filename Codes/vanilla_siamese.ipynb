{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simaese Network\n",
    "- Siamese Network is a type of neural network that uses the same weights while working in tandem on two different input vectors to compute comparable output vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input: 64x3x32x32\n",
    "->\n",
    "conv2d(3, 64, 3, 1, 1): 64x64x32x32\n",
    "->\n",
    "ReLU: 64x64x32x32\n",
    "->\n",
    "MaxPool2d(2, 2): 64x64x16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple CNN\n",
    "'''\n",
    "class FeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conv1:\n",
    "                input kernel = 3\n",
    "                output kernel = 32\n",
    "                kernel size = 3\n",
    "                padding = 1\n",
    "                stride = 1\n",
    "            ...\n",
    "            pool: Maxpooling 2x2\n",
    "            fc: fully connected layer\n",
    "                input: 128 * 8 * 8\n",
    "                output: 128\n",
    "        \"\"\"\n",
    "        super(FeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv3 = nn.Conv2d(64,128,kernel_size=3,padding=1,stride=1)\n",
    "        self.pool = nn.MaxPool2d(2,2) # Maxpooling 2x2\n",
    "        self.fc = nn.Linear(128*8*8,128)\n",
    "        self._intialize_weight_()\n",
    "    def _intialize_weight_(self): # weight initialize\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode = 'fan_in', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias,0)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight, mode = 'fan_in', nonlinearity='relu')\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input vector\n",
    "        Returns:\n",
    "            x: output vector\n",
    "        \"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flatten\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = models.resnet18(pretrained=True)\n",
    "# print(*list(resnet.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Use Resnet18 as feature extractor\n",
    "# \"\"\"\n",
    "# class FeatureExtractorResnet18(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(FeatureExtractorResnet18, self).__init__()\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             resnet: use resnet18 model\n",
    "#             feature_extractor: Sequential\n",
    "#         \"\"\"\n",
    "#         resnet = models.resnet18(pretrained=True)\n",
    "#         self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1]) # 마지막 fc layer 제거\n",
    "#         self.fc = nn.Linear(512, 128)\n",
    "#     def forward(self,x):\n",
    "#         x = self.feature_extractor(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Siamese Network\n",
    "\"\"\"\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_extractor: simple CNN (can be Resnet etc)\n",
    "            fc: \n",
    "                input: 128\n",
    "                output: 1\n",
    "        \"\"\"\n",
    "        self.feature_extractor = FeatureExtractorCNN()\n",
    "        # self.feature_extractor = FeatureExtractorResnet18()\n",
    "        self.fc = nn.Linear(128,1)\n",
    "    def forward(self, input_1, input_2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feat1: feature of input1\n",
    "            feat2: feature of input2\n",
    "            distance: L1 distance\n",
    "            sim: similarity between feat1 and feat2\n",
    "        Returns:\n",
    "            sim\n",
    "        \"\"\"\n",
    "        feat1 = self.feature_extractor(input_1)\n",
    "        feat2 = self.feature_extractor(input_2)\n",
    "        # distance = torch.abs(feat1 - feat2)\n",
    "        # sim = torch.sigmoid(self.fc(distance))\n",
    "        sim = F.cosine_similarity(feat1,feat2)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "deep metric learning\n",
    "    - contrastive loss\n",
    "\"\"\"\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin = 1):\n",
    "        super(ContrastiveLoss,self).__init__()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: contrastive loss\n",
    "        \"\"\"\n",
    "        self.margin = margin\n",
    "    def forward(self, sim, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sim: similarity (result of fc)\n",
    "            label: input name\n",
    "        Returns:\n",
    "            loss.mean(): mean of contrastive loss\n",
    "        \"\"\"\n",
    "        loss = (1 - label) * torch.pow(sim,2) + label * torch.pow(torch.clamp(self.margin - sim, 0),2)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize Model\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = .0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dummy Inputs &  Labels\n",
    "\"\"\"\n",
    "dummy_input1 = torch.randn(4, 3, 64, 64).to(device)  # Batch of 4 images\n",
    "dummy_input2 = torch.randn(4, 3, 64, 64).to(device)  # Batch of 4 images\n",
    "dummy_labels = torch.tensor([1, 0, 1, 0], dtype=torch.float32).to(device)  # 유사한 이미지(1), 다른 이미지(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([0.9454, 0.9413, 0.9394, 0.9425], grad_fn=<SumBackward1>)\n",
      "output.squeeze(): tensor([0.9454, 0.9413, 0.9394, 0.9425], grad_fn=<SqueezeBackward0>)\n",
      "Sim score: [0.94535786 0.94132346 0.9393565  0.94249415]\n",
      "Loss: 0.4452621340751648\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "forward & loss\n",
    "\"\"\"\n",
    "output = model(dummy_input1, dummy_input2)\n",
    "print(\"output:\",output)\n",
    "print(\"output.squeeze():\",output.squeeze())\n",
    "loss = criterion(output.squeeze(),dummy_labels)\n",
    "print(\"Sim score:\", output.squeeze().detach().cpu().numpy())\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dororo99",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
